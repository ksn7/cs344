{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In class, we found that it was not possible to create a neural network that could compute the XOR function. In class, we were attempting this using a single layer neural network, but even with multiple layers XOR cannot be computed. This is because XOR is not linearly separable, which means it cannot be computed with a linear activation function. Functions like AND and OR are linearly separable, which means that when their input data is represented on a plane, a line can be drawn to separate what sets of inputs should produce 1s from those that should produce 0s. This cannot be done for XOR. In this case, it is because the valueo of XOR cannot be computed without the knoweldge of both input values, which is not the case of AND and OR. (By this, I mean that AND is always 0 if either input is 0, and OR is alwasy 1 if either input is 1, so you can know the output while only knowing one of the input values). XOR can only be computed when you know the values of both inputs, and there is no way to assign weights to them so that XOR computes 1 when only one input is a 1. This can be done when using a non-linear activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 506\n",
      "Number of columns: 14\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "\n",
    "boston_df = pd.read_csv(\"https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv\")\n",
    "(rows, columns) = boston_df.shape\n",
    "\n",
    "print(\"Number of rows: \" + str(rows))\n",
    "print(\"Number of columns: \" + str(columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataset before separating, in case it was sorted\n",
    "boston_df.sample(frac=1)\n",
    "\n",
    "# Slice the dataset into 3 portions, for training, validation, and testing\n",
    "training = boston_df[:200]\n",
    "validation = boston_df[200:400]\n",
    "testing = boston_df[400:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### New synthetic feature: job_op. job_op will aim to measure how much opportunity there is for jobs in a town by making a calculation that figures in the mean distance to 5 job centers (dis) and an index of accessibility to radial highways (rad). The thought is that if a town is close to job centers and highways that one could look for jobs in several places and be able to reach it easily. We will calculate this by multiplying the two data points as to get a larger range of values on the scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_df[\"job_op\"] = boston_df[\"dis\"] * boston_df[\"rad\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
