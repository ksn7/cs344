{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i': 0.5, 'am': 0.99, 'spam': 0.99, 'do': 0.3333333333333333, 'not': 0.99, 'like': 0.5, 'that': 0.99, 'spamiam': 0.99, 'green': 0.01, 'eggs': 0.01, 'and': 0.01, 'ham': 0.01}\n",
      "spam, 0.9999984540871616\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This module implements a spam filter based on ideas presented in Paul Graham’s \"A Plan for Spam\".\n",
    "\n",
    "@author ksn7\n",
    "@version Mar 7, 2019\n",
    "'''\n",
    "\n",
    "# Function to create a spam filter\n",
    "def spam_filter(spam_corpus, ham_corpus):\n",
    "    # Create dictionaries for good and bad words\n",
    "    good = {}\n",
    "    bad = {}\n",
    "\n",
    "    # Instead of hashtable, put good and bad words into dictionaries\n",
    "    # Also count the number of words in each corpus\n",
    "    nbad = 0\n",
    "    for msg in spam_corpus:\n",
    "        nbad += 1\n",
    "        for word in msg:\n",
    "            check = word.lower()\n",
    "            if check not in bad:\n",
    "                bad[check] = 1\n",
    "            else:\n",
    "                bad[check] += 1\n",
    "\n",
    "    ngood = 0\n",
    "    for msg in ham_corpus:\n",
    "        ngood += 1\n",
    "        for word in msg:\n",
    "            check = word.lower()\n",
    "            if check not in good:\n",
    "                good[check] = 1\n",
    "            else:\n",
    "                good[check] += 1\n",
    "\n",
    "    # Create list of all words in both corpuses\n",
    "    words = []\n",
    "    for word in bad:\n",
    "        if word not in words:\n",
    "            words.append(word)\n",
    "    for word in good:\n",
    "        if word not in words:\n",
    "            words.append(word)\n",
    "\n",
    "    # make new dictionary story the probability of spam for each word\n",
    "    prob_dict = {}\n",
    "    for word in words:\n",
    "        if word in good:\n",
    "            g = good[word]\n",
    "        else:\n",
    "            g = 0\n",
    "        if word in bad:\n",
    "            b = bad[word]\n",
    "        else:\n",
    "            b = 0\n",
    "        prob = max(0.01, min(0.99, min(1.0, b/nbad) / (min(1.0, g/ngood) + min(1.0, b/nbad))))\n",
    "        prob_dict[word] = prob\n",
    "\n",
    "    return prob_dict\n",
    "               \n",
    "# Sort a message as spam or not spam\n",
    "def sort_msg(msg):\n",
    "    # Check all words are in the filter. If not, prob = 0.4\n",
    "    for word in msg:\n",
    "        if word not in filter:\n",
    "            filter[word] = 0.4\n",
    "            \n",
    "    # Calculate the combined probability for the message\n",
    "    # Calculate the compelement of the probabilities\n",
    "    combined = 1\n",
    "    complement = 1\n",
    "    for word in msg:\n",
    "        combined *= filter[word]\n",
    "        complement *= 1 - filter[word]\n",
    "    \n",
    "    # Calculate the probability of being spam\n",
    "    total = combined / (combined + complement)\n",
    "    if total > 0.9:\n",
    "        status = \"spam\"\n",
    "    else:\n",
    "        status = \"not spam\"\n",
    "    \n",
    "    # Return the spam status and the calculated probability\n",
    "    return status + ', ' + str(total)\n",
    "    \n",
    "# Sample corpuses\n",
    "spam_corpus = [[\"I\", \"am\", \"spam\", \"spam\", \"I\", \"am\"], [\"I\", \"do\", \"not\", \"like\", \"that\", \"spamiam\"]]\n",
    "ham_corpus = [[\"do\", \"i\", \"like\", \"green\", \"eggs\", \"and\", \"ham\"], [\"i\", \"do\"]]\n",
    "    \n",
    "# Test case for building a filter   \n",
    "filter = spam_filter(spam_corpus, ham_corpus)\n",
    "print(filter)\n",
    "\n",
    "# Test case for a new message\n",
    "print(sort_msg([\"I\", \"am\", \"not\", \"spam\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graham's approach is Bayesian because he is estimating the probability of a message being spam based on actual probabilities and based on the whole message. All of the words in the message have weight, some making the message more likely to be spam and others less likely. The probability put out by the algorithm is normalized based on a number of calculations that are all related to the specific words in the message. Another reason this is Bayesian is because the filter will adjust based on the input over time, so the probabilities can change as the evidence changes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This module implements a Bayesian network that compares conditions and wet grass\n",
    "Modeled after network.py by kvlinden\n",
    "\n",
    "@author ksn7\n",
    "@version Mar 6, 2019\n",
    "'''\n",
    "\n",
    "from probability import BayesNet, enumeration_ask\n",
    "\n",
    "# Utility variables\n",
    "T, F = True, False\n",
    "\n",
    "# Bayes Net with values from provided chart\n",
    "grass = BayesNet([\n",
    "    ('Cloudy', '', 0.5),\n",
    "    ('Sprinkler', 'Cloudy', {T: 0.1, F: 0.5}),\n",
    "    ('Rain', 'Cloudy', {T: 0.8, F: 0.2}),\n",
    "    ('Wet', 'Sprinkler Rain', {(T,T): 0.99, (T,F): 0.9, (F,T):0.9, (F,F): 0.0})\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values in full joint probability: There are 4 different variables, each with two different options. Thus the number of values should be 2 * 2 * 2 * 2 = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of values in Bayesian network: Judging based on the number of values represented in the Bayes Net figure, a Bayesian network can store all the information it needs to make the necessary computations with 9 values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part d \n",
    "#### hand compositions uploaded in homework2.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Cloudy)\n",
      "False: 0.5, True: 0.5\n",
      "\n",
      "P(Sprinkler | cloudy)\n",
      "False: 0.9, True: 0.1\n",
      "\n",
      "P(Cloudy | the sprinkler is running and it’s not raining)\n",
      "False: 0.952, True: 0.0476\n",
      "\n",
      "P(WetGrass | it’s cloudy, the sprinkler is running and it’s raining)\n",
      "False: 0.01, True: 0.99\n",
      "\n",
      "P(Cloudy | the grass is not wet)\n",
      "False: 0.639, True: 0.361\n"
     ]
    }
   ],
   "source": [
    "# Compute P(Cloudy)\n",
    "print(\"P(Cloudy)\")\n",
    "print(enumeration_ask('Cloudy', dict(), grass).show_approx())\n",
    "\n",
    "# Compute P(Sprinkler | cloudy)\n",
    "print(\"\\nP(Sprinkler | cloudy)\")\n",
    "print(enumeration_ask('Sprinkler', dict(Cloudy=T), grass).show_approx())\n",
    "\n",
    "# Compute P(Cloudy | the sprinkler is running and it’s not raining)\n",
    "print(\"\\nP(Cloudy | the sprinkler is running and it’s not raining)\")\n",
    "print(enumeration_ask('Cloudy', dict(Sprinkler=T, Rain=F), grass).show_approx())\n",
    "\n",
    "# Compute P(WetGrass | it’s cloudy, the sprinkler is running and it’s raining)\n",
    "print(\"\\nP(WetGrass | it’s cloudy, the sprinkler is running and it’s raining)\")\n",
    "print(enumeration_ask('Wet', dict(Cloudy=T, Sprinkler=T, Rain=T), grass).show_approx())\n",
    "\n",
    "# Compute P(Cloudy | the grass is not wet)\n",
    "print(\"\\nP(Cloudy | the grass is not wet)\")\n",
    "print(enumeration_ask('Cloudy', dict(Wet=F), grass).show_approx())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
